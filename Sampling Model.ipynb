{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4113239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import keras\n",
    "from keras.metrics import MeanIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c607e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_X = 256\n",
    "SIZE_Y = 256\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72168436",
   "metadata": {},
   "source": [
    "# Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad6b14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture training image info as a list\n",
    "train_images = []\n",
    "\n",
    "for directory_path in glob.glob(\"new_images\"):\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "        img = cv2.imread(img_path, 1)\n",
    "        img = cv2.resize(img, (SIZE_Y, SIZE_X), interpolation = cv2.INTER_NEAREST)\n",
    "        train_images.append(img)\n",
    "    \n",
    "# Convert list to array for machine learning processing        \n",
    "train_images = np.array(train_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a517e703",
   "metadata": {},
   "source": [
    "# Loading masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e15311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture mask/label info as a list\n",
    "train_masks = []\n",
    "\n",
    "for directory_path in glob.glob(\"new_masks\"):\n",
    "    for mask_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "        mask = cv2.imread(mask_path, 0)\n",
    "        mask = cv2.resize(mask, (SIZE_Y, SIZE_X), interpolation = cv2.INTER_NEAREST)\n",
    "        mask[mask <= 15] = 0\n",
    "        mask[mask >= 200] = 255\n",
    "        train_masks.append(mask)\n",
    "        \n",
    "# Convert list to array for machine learning processing          \n",
    "train_masks = np.array(train_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ffa9b1",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e1c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "n, h, w = train_masks.shape\n",
    "train_masks_reshaped = train_masks.reshape(-1, 1)\n",
    "train_masks_reshaped_encoded = labelencoder.fit_transform(train_masks_reshaped)\n",
    "train_masks_encoded_original_shape = train_masks_reshaped_encoded.reshape(n, h, w)\n",
    "\n",
    "np.unique(train_masks_encoded_original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d721d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks_input = np.expand_dims(train_masks_encoded_original_shape, axis = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d84a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_images, train_masks_input, test_size = 0.10, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a2109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = np.unique(train_masks[0], return_counts = True)\n",
    "\n",
    "print(\"Class values in the dataset are ... \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a568e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_masks_cat = to_categorical(train_masks_input, num_classes=n_classes)\n",
    "y_train_cat = train_masks_cat.reshape((train_masks_input.shape[0], train_masks_input.shape[1], train_masks_input.shape[2], n_classes))\n",
    "\n",
    "test_masks_cat = to_categorical(y_test, num_classes=n_classes)\n",
    "y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc84b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    # Flatten the input tensors\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    \n",
    "    # Calculate intersection and union of the flattened tensors\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f)\n",
    "    \n",
    "    # Calculate Dice coefficient\n",
    "    dice_coef = (2.0 * intersection + smooth) / (union + smooth)\n",
    "    \n",
    "    return dice_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b8d41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "activation = 'softmax'\n",
    "\n",
    "LR = 0.001\n",
    "optim =  keras.optimizers.Adam(LR)\n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5), dice_coef]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb26084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Exp_loss(y_true, y_pred):\n",
    "  y_pred = tf.nn.softmax(y_pred)\n",
    "\n",
    "  true = 0.8 * tf.math.exp(-1 * tf.math.multiply(y_true, y_pred))\n",
    "  wrong = tf.math.exp(-1 * tf.math.multiply((1 - y_true), (1 - y_pred)))\n",
    "  loss = tf.reduce_mean(true + wrong)\n",
    "  \n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8da364",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3ea345",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE1 = 'resnet101'\n",
    "preprocess_input1 = sm.get_preprocessing(BACKBONE1)\n",
    "\n",
    "X_train1 = preprocess_input1(train_images)\n",
    "X_test1 = preprocess_input1(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a542905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet_collection import models\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True # enable dynamic GPU memory allocation\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "model = models.unet_2d((256, 256, 3), [64, 128, 256, 512, 1024], n_labels = 2,\n",
    "                      stack_num_down = 2, stack_num_up = 2, backbone='ResNet101',\n",
    "                      activation='ReLU', output_activation = 'Softmax',\n",
    "                      batch_norm = True, pool = 'max', unpool = 'bilinear', name = 'unet-main')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cbdc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optim, Exp_loss, metrics = metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad0d40d",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32830fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model.fit(X_train1,\n",
    "          y_train_cat,\n",
    "          batch_size = 8,\n",
    "          epochs = 50,\n",
    "          validation_split = 0.125)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dbf5ce",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3fc4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_images)\n",
    "y_pred_argmax = np.argmax(y_pred, axis = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cec713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "IOU_keras = MeanIoU(num_classes = n_classes)\n",
    "IOU_keras.update_state(test_masks_input[:, :, :, 0], y_pred_argmax)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3ba7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate I0U for each class...\n",
    "values = np.array(IOU_keras.get_weights()).reshape(n_classes, n_classes)\n",
    "print(values)\n",
    "class1_IoU = values[0,0] / (values[0,0] + values[0,1] + values[1,0])\n",
    "class2_IoU = values[1,1] / (values[1,1] + values[1,0]  + values[0,1])\n",
    "\n",
    "print(\"IoU for class1 is: \", class1_IoU)\n",
    "print(\"IoU for class2 is: \", class2_IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8d6a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history1.history['loss']\n",
    "val_loss = history1.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history1.history['iou_score']\n",
    "val_acc = history1.history['val_iou_score']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training IOU')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation IOU')\n",
    "plt.title('Training and validation IOU')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('IOU')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f919678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test some random images\n",
    "import random\n",
    "test_img_number = random.randint(0, len(X_test1) - 1)\n",
    "print(test_img_number)\n",
    "test_img = X_test1[test_img_number]\n",
    "ground_truth = test_masks_input[test_img_number]\n",
    "test_img_input = np.expand_dims(test_img, 0)\n",
    "\n",
    "test_img_input1 = preprocess_input1(test_img_input)\n",
    "\n",
    "test_pred1 = model.predict(test_img_input1)\n",
    "test_prediction1 = np.argmax(test_pred1, axis=3)[0,:,:]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[:,:,0], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(ground_truth[:,:,0], cmap='jet')\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(test_prediction1, cmap='jet')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
